\section{Experiment Design}

\subsection{MOEA/D and Bet-and-Run}

In this work, the integrate of both frameworks, the MOEA/D the Bet-and-Run, is analized. First, the implementation of MOEA/D is discussed. Then the implementation of the Bet-and-Run followed by the discussion of how to integratate them.

\subsubsection{MOEA/D}

In this paper, two different MOEA/D combinations found in the literature  were studied. These combinations are the original MOEA/D~\cite{zhang2007moea} and MOEA/D-DE~\cite{li2009multiobjective}. 

The first modification was to change the parameter control $H$ of the simplex-lattice design (SLD) that is used to generate the weight vectors W. For the 2-objective problem benchmark functions it was set as \textit{199}, while for the 3-objective problem benchmark functions, \textit{19}. Those vales for the $H$ parameter were chosen so that the number of sub-problems and the size of incumbent solutions are equal to \textit{200}, following default settings as in the works of Brockhoff et. al~\cite{brockhoff2015benchmarking} and Tanabe et. al~\cite{tanabe2018analysis}. The other modification was to use an archive, that stores all non-dominated solutions found during the search process.(????????). 

Here, the integration of On-line Resource Allocation (ONRA), proposed in the context of MOEA/D by \cite{zhou2016all} was also considered. The resource distribution when using ONRA is allocated using an adaptive strategy aiming to adjust the behavior of an algorithm in on-line manner to suit the problem in question. Although, other strategies were proposed in the work of Zhou, ONRA was the one that perfomed better among all strategies proposed. The ONRA strategy is concerned with the distribution of resources in an execution of MOEA/D. Different amounts of resources are considered to different sub-problems, following the assumption that some sub-problems can be more difficult to approximate that others. 

\subsubsection{Bet-and-Run}

In this work, the Bet-and-run framework implemented follows the results found  by Friedrich et. al~\cite{friedrich2017generic}. They studied different combinations strategies that are diverse on the amount of resources assigned for phase 1 and 2. 

The best overall strategy found is the one that uses 40\% of the total budget available on short runs (phase 1) and then run the most prominent one (phase 2) with the remaining 60\% of the budget found. One adjustment was made to better fit the context of MOP and MOEA/D which is defining the budget as the number of interactions, instead of using time as the budget as Friedrich et. al used.

%Phase 1 of the bet-and-run strategy is using the epsilon indicator. 40 instances.
%It needs two Pareto sets. The first is the Pareto set of a bet instance while the other is the Pareto set from the control algorithm executed with 1% of the number of interactions. 
%Phase 2 uses the 60% rest of max interactions.


%

\subsection{Experimental Setting}


The DTLZ~\cite{deb2005scalable} and the ZDT~\cite{zitzler2000comparison},test problems were used in the analysis. For the first the number of objectives used was two three. According to~\cite{deb2005scalable}, for the DTLZ problems, the number of position variables D was set to $k = 5$ for the DTLZ1 problem, $k = 7$ for the DTLZ2 problem and $k = 10$ for the other DTLZ problems, where the number of variables $D = n_f + k -1$. For the ZDT the number of variable $D = 11$.

Here termination criteria was set to the maximum of iterations, with value of \textit{300} interactions, which leads to a number of functions evaluations of \textit{60200} in the case of the 2-objective problems, while for the 3-objective problems, the number of evaluations lead was \textit{63210}.

The hyper-volume (HV) indicator~\cite{zitzler1998multiobjective} was used for evaluating the quality of a set of obtained non-dominated solutions $DS$. Before calculating the HV value, the objective function vector $f(x)$ of each $x \in DS$ was scaled between 0 and 1, as suggested in~\cite{ishibuchi2018specify}. Therefore the reference point used, based on the work of Ishibuchi et. at was defined given the value $H$:
\begin{itemize}
	\item For 2-objectives: $H = 199$, which leads to a reference point of $(1+1/H, 1+1/H) = (1.005, 1.005)$
	\item For 3-objectives: $H = 99$, which leads to a reference point of $(1+1/H, 1+1/H) = (1.010, 1.010)$
\end{itemize}



The following combinations of algorithms (MOEA/D-DE or MOEA/D) were tested:

\begin{itemize}
	\item MOEA/D-DE
	\item MOEA/D-DE with Bet-and-Run strategy
	\item MOEA/D-DE with ONRA
	\item MOEA/D-DE with Bet-and-Run strategy and ONRA
	\item MOEA/D
	\item MOEA/D with Bet-and-Run strategy
	\item MOEA/D with ONRA
	\item MOEA/D with Bet-and-Run strategy and ONRA
\end{itemize}

For each combinations above,, the search was repeated 30 times, and the Kruskal-Wallis XXX box-plot XXXX.
%
%Configurations and Parameters
%
%Control - Based on the common variation: MOEA/D (variation1) and MOEA/D-DE as in preset\_moead
%Control and ONRA - parameters: dt = 20
%Ben-and-run
%Ben-and-run and ONRA - parameters: dt = 20
%
%Dt - interval that control the resources allocation. From the proposal paper, there is no much sensibility.
%Decomposition method used - SLD, with H being 199 for 2D and 19 for 3D 
%number of dimensions - 60 
%All other parameters are defined by  preset\_moead
%
%Bet-and-run
%
%Phase 1 of the bet-and-run strategy is using the epsilon indicator. 40 instances.
%It needs two Pareto sets. The first is the Pareto set of a bet instance while the other is the Pareto set from the control algorithm executed with 1\% of the number of interactions. 
%Phase 2 uses the 60\% rest of max interactions.
%
%\section{Evaluation Metrics}
%
%Evaluation Metrics
%
%Unary Indicators
%
%- Measure Pareto Sets independently.
%- Power is restricted.
%- Cannot tell in general if a set is better than another.
%- Focus on problem dependent and specifics.
%- Assumptions and knowledge should be specified.
%1. Hyper-volume.
%2. Error ratio.
%3. Distance from reference set.
%
%Binary Indicators
%
%- Theoretically have no limitations.
%- Analysis and presentation of results more difficult.
%
%1. R1, R2, R3 indicators.
%2. $\varepsilon$-Indicator.
%3. Binary Hyper-volume.
%
%Hypervolume
%Considerations
%
%- Is complete - If, and only if $HV(A) > HV(B) \implies A$ is not worse than $B$.
%- Is weakly compatible - $HV(A) > HV(B) \implies \not B$ dominates $A$.
%- Assumptions - All points of a Pareto Set under consideration dominate the reference point.
%- @ishibuchi2018specify proposed a method to specify the reference point from a viewpoint of fair performance comparison.
%
%Considerations
%- A large population size is **always** more beneficial than a small one.
%- Measures both the convergence toward the Pareto Front and the diversity of non-dominated solutions.
%- A monotonic increase of the hyper-volume over time cannot always be ensured.
%- For MOEA/D that is always true.
%
%$\varepsilon$-Indicator
%Considerations
%- It compares 2 Pareto Sets.
%- It indicates which set is better and how much better
%- If A is better than B $\implies I_{\varepsilon}(B,A) > 0$.
%- If $I_{\varepsilon}(A,B) \leq 0$ and $I_{\varepsilon}(B,A) > 0 \implies A$ is better than $B$.
%
%The benchmark used are the DTLZ and the ZDT group of functions.
%
%DTLZ are easy~\cite{bezerra2015comparing}.
%
